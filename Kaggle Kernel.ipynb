{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From kaggle\n",
    "https://www.kaggle.com/fmarazzi/baseline-keras-cnn-roc-fast-10min-0-925-lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''For preprocessing images'''\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import glob\n",
    "'''For CNN'''\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications import MobileNet\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 96\n",
    "train_data_size = 4000\n",
    "test_data_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(img):\n",
    "    # padding\n",
    "    longer_side = max(img.size)\n",
    "    horizontal_padding = (longer_side - img.size[0]) / 2\n",
    "    vertical_padding = (longer_side - img.size[1]) / 2\n",
    "    img = img.crop(\n",
    "        (\n",
    "            -horizontal_padding,\n",
    "            -vertical_padding,\n",
    "            img.size[0] + horizontal_padding,\n",
    "            img.size[1] + vertical_padding\n",
    "        )\n",
    "    )\n",
    "    # resizing to standardized size\n",
    "    img = img.resize([image_size,image_size],Image.ANTIALIAS) \\\n",
    "    # plt.imshow(img) # To see the image being standardized.\n",
    "    \n",
    "    # converting image to numpy array\n",
    "    img.load()\n",
    "    img = np.asarray(img, dtype=\"int32\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function():\n",
    "    for filename in glob.glob('input/subset_data/train/*.tif'):\n",
    "        img =Image.open(filename)\n",
    "        img = standardize(img)\n",
    "        print(img.shape)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading data'''\n",
    "def get_id_from_filename(filename):\n",
    "    id = filename.split(\"/\")[-1]\n",
    "    id = id.split(\".\")[0]\n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    names = []\n",
    "    # Change first number base on number of training examples\n",
    "    X_train = np.empty((train_data_size,image_size,image_size,3), dtype=\"int32\")\n",
    "    Y_train = np.empty(shape=(train_data_size,2),dtype=\"int32\")\n",
    "\n",
    "    i = 0\n",
    "    for filename in glob.glob('input/subset_data/train/*.tif'):\n",
    "        names.append(get_id_from_filename(filename))\n",
    "        img =Image.open(filename)\n",
    "        img = standardize(img)\n",
    "        X_train[i-1] = img\n",
    "        i += 1\n",
    "        \n",
    "    with open('input/subset_data/train_labels_full.csv') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        next(readCSV, None)\n",
    "        for row in readCSV:\n",
    "            name = row[0]\n",
    "            if name in names:\n",
    "                label = int(row[1])\n",
    "                if label == 0:\n",
    "                    Y_train[names.index(name)] = np.array([1,0]) # means 0\n",
    "                elif label == 1:\n",
    "                    Y_train[names.index(name)] = np.array([0,1]) # means 1\n",
    "    return X_train,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test():\n",
    "    names = []\n",
    "    # Change first number base on number of training examples\n",
    "    X_test = np.empty((test_data_size,image_size,image_size,3), dtype=\"int32\")\n",
    "    Y_test = np.empty(shape=(test_data_size,2),dtype=\"int32\")\n",
    "\n",
    "    i = 0\n",
    "    for filename in glob.glob('input/subset_data/test_with_outputs/*.tif'):\n",
    "        names.append(get_id_from_filename(filename))\n",
    "        img =Image.open(filename)\n",
    "        img = standardize(img)\n",
    "        X_test[i-1] = img\n",
    "        i += 1\n",
    "        \n",
    "    with open('input/subset_data/train_labels_full.csv') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        next(readCSV, None)\n",
    "        for row in readCSV:\n",
    "            name = row[0]\n",
    "            if name in names:\n",
    "                label = int(row[1])\n",
    "                if label == 0:\n",
    "                    Y_test[names.index(name)] = np.array([1,0]) # means 0\n",
    "                elif label == 1:\n",
    "                    Y_test[names.index(name)] = np.array([0,1]) # means 1\n",
    "    return X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (4000, 96, 96, 3)\n",
      "Y_train shape:  (4000, 2)\n",
      "X_test shape:  (1000, 96, 96, 3)\n",
      "Y_test shape:  (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig,Y_train_orig = load_train()\n",
    "X_test_orig,Y_test_orig = load_test()\n",
    "\n",
    "# Normalizing for faster convergence\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "Y_train = Y_train_orig\n",
    "Y_test = Y_test_orig\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"Y_train shape: \", Y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"Y_test shape: \", Y_test.shape)\n",
    "\n",
    "# To check values inside.\n",
    "# print(X_train)\n",
    "# print(Y_train)\n",
    "# print(X_test)\n",
    "# print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "### Model structure (optimizer: Adam):\n",
    "\n",
    "- Input\n",
    "- [Conv2D*3 -> MaxPool2D -> Dropout] x3 --> (filters = 16, 32, 64)\n",
    "- Flatten\n",
    "- Dense (256)\n",
    "- Dropout\n",
    "- Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "kernel_size = (3,3)\n",
    "pool_size= (2,2)\n",
    "first_filters = 32\n",
    "second_filters = 64\n",
    "third_filters = 128\n",
    "\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (image_size, image_size, 3)))\n",
    "model.add(Conv2D(first_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size)) \n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "# model.add(Dense(1, activation = \"sigmoid\"))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(Adam(0.01), loss = \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 94, 94, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 92, 92, 32)        9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 92, 92, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 92, 92, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 46, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 46, 46, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 44, 44, 64)        18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 44, 44, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 44, 44, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 42, 42, 64)        36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 42, 42, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 19, 19, 128)       73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 19, 19, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 17, 17, 128)       147456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 2,386,946\n",
      "Trainable params: 2,385,602\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/13\n",
      "4000/4000 [==============================] - 13s 3ms/step - loss: 0.8613 - acc: 0.5473 - val_loss: 1.0673 - val_acc: 0.5850\n",
      "Epoch 2/13\n",
      "4000/4000 [==============================] - 9s 2ms/step - loss: 0.7473 - acc: 0.5555 - val_loss: 0.7508 - val_acc: 0.5520\n",
      "Epoch 3/13\n",
      "4000/4000 [==============================] - 9s 2ms/step - loss: 0.7191 - acc: 0.5635 - val_loss: 0.9722 - val_acc: 0.5020\n",
      "Epoch 4/13\n",
      "4000/4000 [==============================] - 9s 2ms/step - loss: 0.7114 - acc: 0.5635 - val_loss: 0.6715 - val_acc: 0.6040\n",
      "Epoch 5/13\n",
      "4000/4000 [==============================] - 9s 2ms/step - loss: 0.6925 - acc: 0.5740 - val_loss: 0.6731 - val_acc: 0.6030\n",
      "Epoch 6/13\n",
      "4000/4000 [==============================] - 9s 2ms/step - loss: 0.6914 - acc: 0.5717 - val_loss: 0.6712 - val_acc: 0.6070\n",
      "Epoch 7/13\n",
      "4000/4000 [==============================] - 9s 2ms/step - loss: 0.6829 - acc: 0.5875 - val_loss: 0.6777 - val_acc: 0.6070\n",
      "Epoch 8/13\n",
      "4000/4000 [==============================] - 9s 2ms/step - loss: 0.6794 - acc: 0.5877 - val_loss: 0.6737 - val_acc: 0.6060\n",
      "Epoch 9/13\n",
      "4000/4000 [==============================] - 9s 2ms/step - loss: 0.6790 - acc: 0.5887 - val_loss: 0.6725 - val_acc: 0.6070\n",
      "Epoch 10/13\n",
      "4000/4000 [==============================] - 9s 2ms/step - loss: 0.6799 - acc: 0.5897 - val_loss: 0.6766 - val_acc: 0.6060\n",
      "Epoch 11/13\n",
      "4000/4000 [==============================] - 9s 2ms/step - loss: 0.6782 - acc: 0.5887 - val_loss: 0.6755 - val_acc: 0.6070\n",
      "Epoch 12/13\n",
      "4000/4000 [==============================] - 9s 2ms/step - loss: 0.6763 - acc: 0.5837 - val_loss: 0.6713 - val_acc: 0.6070\n",
      "Epoch 13/13\n",
      "4000/4000 [==============================] - 9s 2ms/step - loss: 0.6772 - acc: 0.5910 - val_loss: 0.6731 - val_acc: 0.6070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f918c05f0f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size = 32, epochs = 13, verbose = 1, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
