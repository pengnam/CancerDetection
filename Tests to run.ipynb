{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''For preprocessing images'''\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import glob\n",
    "'''For CNN'''\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(img):\n",
    "    # padding\n",
    "    longer_side = max(img.size)\n",
    "    horizontal_padding = (longer_side - img.size[0]) / 2\n",
    "    vertical_padding = (longer_side - img.size[1]) / 2\n",
    "    img = img.crop(\n",
    "        (\n",
    "            -horizontal_padding,\n",
    "            -vertical_padding,\n",
    "            img.size[0] + horizontal_padding,\n",
    "            img.size[1] + vertical_padding\n",
    "        )\n",
    "    )\n",
    "    # resizing to standardized size\n",
    "    img = img.resize([256,256],Image.ANTIALIAS) \\\n",
    "    # plt.imshow(img) # To see the image being standardized.\n",
    "    \n",
    "    # converting image to numpy array\n",
    "    img.load()\n",
    "    img = np.asarray(img, dtype=\"int32\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function():\n",
    "    for filename in glob.glob('input/subset_data/train/*.tif'):\n",
    "        img =Image.open(filename)\n",
    "        img = standardize(img)\n",
    "        print(img.shape)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading data'''\n",
    "def get_id_from_filename(filename):\n",
    "    id = filename.split(\"\\\\\")[-1]\n",
    "    id = id.split(\".\")[0]\n",
    "    return id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Code:\n",
    "- If number of training example changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    names = []\n",
    "    # Change first number base on number of training examples\n",
    "    X_train = np.empty((450,256,256,3), dtype=\"int32\")\n",
    "    Y_train = np.empty(shape=(450,2),dtype=\"int32\")\n",
    "\n",
    "    i = 0\n",
    "    for filename in glob.glob('input/subset_data/train/*.tif'):\n",
    "        names.append(get_id_from_filename(filename))\n",
    "        img =Image.open(filename)\n",
    "        img = standardize(img)\n",
    "        X_train[i-1] = img\n",
    "        i += 1\n",
    "        \n",
    "    with open('input/subset_data/train_labels_full.csv') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        next(readCSV, None)\n",
    "        for row in readCSV:\n",
    "            name = row[0]\n",
    "            if name in names:\n",
    "                label = int(row[1])\n",
    "                if label == 0:\n",
    "                    Y_train[names.index(name)] = np.array([1,0]) # means 0\n",
    "                elif label == 1:\n",
    "                    Y_train[names.index(name)] = np.array([0,1]) # means 1\n",
    "    return X_train,Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Code:\n",
    "- If number of training example changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test():\n",
    "    names = []\n",
    "    # Change first number base on number of training examples\n",
    "    X_test = np.empty((50,256,256,3), dtype=\"int32\")\n",
    "    Y_test = np.empty(shape=(50,2),dtype=\"int32\")\n",
    "\n",
    "    i = 0\n",
    "    for filename in glob.glob('input/subset_data/test_with_outputs/*.tif'):\n",
    "        names.append(get_id_from_filename(filename))\n",
    "        img =Image.open(filename)\n",
    "        img = standardize(img)\n",
    "        X_test[i-1] = img\n",
    "        i += 1\n",
    "        \n",
    "    with open('input/subset_data/train_labels_full.csv') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        next(readCSV, None)\n",
    "        for row in readCSV:\n",
    "            name = row[0]\n",
    "            if name in names:\n",
    "                label = int(row[1])\n",
    "                if label == 0:\n",
    "                    Y_test[names.index(name)] = np.array([1,0]) # means 0\n",
    "                elif label == 1:\n",
    "                    Y_test[names.index(name)] = np.array([0,1]) # means 1\n",
    "    return X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (450, 256, 256, 3)\n",
      "Y_train shape:  (450, 2)\n",
      "X_test shape:  (50, 256, 256, 3)\n",
      "Y_test shape:  (50, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = load_train()\n",
    "X_test, Y_test = load_test()\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"Y_train shape: \", Y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"Y_test shape: \", Y_test.shape)\n",
    "# To check values inside.\n",
    "# print(X_train)\n",
    "# print(Y_train)\n",
    "# print(X_test)\n",
    "# print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainingModel(input_shape):\n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(8, (4, 4), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((8, 8), name='max_pool0')(X)\n",
    "    \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(16, (2, 2), strides = (1, 1), name = 'conv1')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((4, 4), name='max_pool1')(X)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(2, activation='softmax', name='fc')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='trainingModel')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingModel = TrainingModel((X_train.shape[1],X_train.shape[2],X_train.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingModel.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple CNN\n",
    "- set epoch to 50 and record the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "450/450 [==============================] - 43s 95ms/step - loss: 0.8821 - acc: 0.5489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23622632208>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingModel.fit(x = X_train, y = Y_train, epochs = 50, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 2s 41ms/step\n",
      "\n",
      "Loss = 0.723783688545227\n",
      "Test Accuracy = 0.54\n"
     ]
    }
   ],
   "source": [
    "preds = trainingModel.evaluate(x = X_test, y = Y_test)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_model = keras.applications.vgg16.VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the type\n",
    "type(vgg16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your own input format \n",
    "X_input = Input(shape=(256,256,3),name = 'image_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vgg16_conv = vgg16_model(X_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the fully-connected layers \n",
    "X = Flatten(name='flatten')(output_vgg16_conv)\n",
    "X = Dense(2048, activation='relu', name='fc1')(X)\n",
    "X = Dense(2048, activation='relu', name='fc2')(X)\n",
    "X = Dense(2, activation='softmax', name='predictions')(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Model(inputs=X_input, outputs=X,name='myModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.fit(x = X_train, y = Y_train, epochs = 50, batch_size = 32, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = my_model.evaluate(x = X_test, y = Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptionV3_model = keras.applications.inception_v3.InceptionV3(weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(inceptionV3_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the other layers, let last few layers to be trainable\n",
    "for layer in inceptionV3_model.layers[:290]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your own input format\n",
    "X_input = Input(shape=(256,256,3),name = 'image_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_inceptionV3_conv = inceptionV3_model(X_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras recommended application\n",
    "X = GlobalAveragePooling2D()(output_inceptionV3_conv)\n",
    "X = Dense(1024, activation='relu')(X)\n",
    "X = Dense(4, activation='softmax', name='predictions')(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Model(inputs=X_input, outputs=X,name='myModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.fit(x = X_train, y = Y_train, epochs = 50, batch_size = 32, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = my_model.evaluate(x = X_test, y = Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To resolve the issue of BN in keras layers\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model = keras.applications.resnet50.ResNet50(weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(resnet50_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the other layers\n",
    "for layer in resnet50_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your own input format \n",
    "X_input = Input(shape=(256,256,3),name = 'image_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_resnet50_conv = resnet50_model(X_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = GlobalAveragePooling2D()(output_resnet50_conv)\n",
    "# X = Dense(4, activation='softmax', name='predictions')(X)\n",
    "X = Flatten(name='flatten')(output_resnet50_conv)\n",
    "X = Dense(2048, activation='relu', name='fc1')(X)\n",
    "X = Dropout(0.7)(X)\n",
    "X = Dense(1024, activation='relu', name='fc2')(X)\n",
    "X = Dropout(0.7)(X)\n",
    "X = Dense(2, activation='softmax', name='predictions')(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Model(inputs=X_input, outputs=X,name='myModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.fit(x = X_train, y = Y_train, epochs = 50, batch_size = 32, validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = my_model.evaluate(x = X_test, y = Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
