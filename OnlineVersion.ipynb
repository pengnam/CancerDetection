{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6de38c0ff88b6738c5c8751c722c9b489602d88"
   },
   "source": [
    "## Baseline Keras CNN with 160k samples\n",
    "Heavily inspired by https://www.kaggle.com/hrmello/cnn-classification-80-accuracy\n",
    "\n",
    "Thanks to @Marsh for https://www.kaggle.com/vbookshelf/cnn-how-to-use-160-000-images-without-crashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from glob import glob \n",
    "from skimage.io import imread\n",
    "import gc\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d06b98f87cfa19e2548b0d3a558128d563942e1b"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "base_tile_dir = 'input/subset_data/train/'\n",
    "df = pd.DataFrame({'path': glob(os.path.join(base_tile_dir,'*.tif'))})\n",
    "df['id'] = df.path.map(lambda x: x.split('/')[3].split(\".\")[0])\n",
    "labels = pd.read_csv(\"input/subset_data/train_labels_full.csv\")\n",
    "df_data = df.merge(labels, on = \"id\", how=\"left\")\n",
    "\n",
    "# removing this image because it caused a training error previously\n",
    "df_data = df_data[df_data['id'] != 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2']\n",
    "\n",
    "# removing this image because it's black\n",
    "df_data = df_data[df_data['id'] != '9369c7278ec8bcc6c880d99194de09fc2bd4efbe']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0bfaeb9d367e1b720fd81623e9248c3ff7bb0b5e"
   },
   "source": [
    "# Split X and y in train/test and build folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "d60413a93a292379227e2b8979d2abeed70ed718"
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 1500 # load 80k negative examples\n",
    "\n",
    "# take a random sample of class 0 with size equal to num samples in class 1\n",
    "df_0 = df_data[df_data['label'] == 0].sample(SAMPLE_SIZE, random_state = 101)\n",
    "# filter out class 1\n",
    "df_1 = df_data[df_data['label'] == 1].sample(SAMPLE_SIZE, random_state = 101)\n",
    "\n",
    "# concat the dataframes\n",
    "df_data = shuffle(pd.concat([df_0, df_1], axis=0).reset_index(drop=True))\n",
    "\n",
    "# train_test_split # stratify=y creates a balanced validation set.\n",
    "y = df_data['label']\n",
    "df_train, df_val = train_test_split(df_data, test_size=0.10, random_state=101, stratify=y)\n",
    "\n",
    "# Create directories\n",
    "train_path = 'base_dir/train'\n",
    "valid_path = 'base_dir/valid'\n",
    "test_path = '../input/test'\n",
    "for fold in [train_path, valid_path]:\n",
    "    for subf in [\"0\", \"1\"]:\n",
    "        os.makedirs(os.path.join(fold, subf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "e85d943cfc261cca54b34550554549244f947400"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01b68184a51c35cc1850bc7c9b133ec38eff2729</th>\n",
       "      <td>input/subset_data/train/01b68184a51c35cc1850bc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b9665f6da8635ef33e8b16442f47e41ac9dd27a5</th>\n",
       "      <td>input/subset_data/train/b9665f6da8635ef33e8b16...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59775d2ce71b4619184559ff15288e490751eb25</th>\n",
       "      <td>input/subset_data/train/59775d2ce71b4619184559...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3b74926b185597229ffe3cb09ec81857c89871f2</th>\n",
       "      <td>input/subset_data/train/3b74926b185597229ffe3c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7d0e0952e5133c393710c6ae9913812275ec6ae3</th>\n",
       "      <td>input/subset_data/train/7d0e0952e5133c393710c6...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       path  \\\n",
       "id                                                                                            \n",
       "01b68184a51c35cc1850bc7c9b133ec38eff2729  input/subset_data/train/01b68184a51c35cc1850bc...   \n",
       "b9665f6da8635ef33e8b16442f47e41ac9dd27a5  input/subset_data/train/b9665f6da8635ef33e8b16...   \n",
       "59775d2ce71b4619184559ff15288e490751eb25  input/subset_data/train/59775d2ce71b4619184559...   \n",
       "3b74926b185597229ffe3cb09ec81857c89871f2  input/subset_data/train/3b74926b185597229ffe3c...   \n",
       "7d0e0952e5133c393710c6ae9913812275ec6ae3  input/subset_data/train/7d0e0952e5133c393710c6...   \n",
       "\n",
       "                                          label  \n",
       "id                                               \n",
       "01b68184a51c35cc1850bc7c9b133ec38eff2729      1  \n",
       "b9665f6da8635ef33e8b16442f47e41ac9dd27a5      0  \n",
       "59775d2ce71b4619184559ff15288e490751eb25      0  \n",
       "3b74926b185597229ffe3cb09ec81857c89871f2      1  \n",
       "7d0e0952e5133c393710c6ae9913812275ec6ae3      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the id as the index in df_data\n",
    "df_data.set_index('id', inplace=True)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c6683c986522a604dc1a715687b1d1c621628e94"
   },
   "outputs": [],
   "source": [
    "for image in df_train['id'].values:\n",
    "    # the id in the csv file does not have the .tif extension therefore we add it here\n",
    "    fname = image + '.tif'\n",
    "    label = str(df_data.loc[image,'label']) # get the label for a certain image\n",
    "    src = os.path.join('input/subset_data/train', fname)\n",
    "    dst = os.path.join(train_path, label, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "for image in df_val['id'].values:\n",
    "    fname = image + '.tif'\n",
    "    label = str(df_data.loc[image,'label']) # get the label for a certain image\n",
    "    src = os.path.join('input/subset_data/train', fname)\n",
    "    dst = os.path.join(valid_path, label, fname)\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "145ef9177524908eb5656fd1deb55a82aeb01973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2700 images belonging to 2 classes.\n",
      "Found 300 images belonging to 2 classes.\n",
      "Found 300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SIZE = 96\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)\n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=lambda x:(x - x.mean()) / x.std() if x.std() > 0 else x,\n",
    "                            horizontal_flip=True,\n",
    "                            vertical_flip=True)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=train_batch_size,\n",
    "                                        class_mode='binary')\n",
    "\n",
    "val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=val_batch_size,\n",
    "                                        class_mode='binary')\n",
    "\n",
    "# Note: shuffle=False causes the test dataset to not be shuffled\n",
    "test_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=1,\n",
    "                                        class_mode='binary',\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "037766b4d6d71232ff280ee04aee45671db93b7a"
   },
   "source": [
    "# Define the model \n",
    "**Model structure (optimizer: Adam):**\n",
    "\n",
    "* In \n",
    "* [Conv2D*3 -> MaxPool2D -> Dropout] x3 --> (filters = 16, 32, 64)\n",
    "* Flatten \n",
    "* Dense (256) \n",
    "* Dropout \n",
    "* Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "1d252eb588aaf888171ff82b332efd4a0880cab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "kernel_size = (3,3)\n",
    "pool_size= (2,2)\n",
    "first_filters = 32\n",
    "second_filters = 64\n",
    "third_filters = 128\n",
    "\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "model.add(Conv2D(first_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size)) \n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "#model.add(GlobalAveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(Adam(0.01), loss = \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56a7cce49809eae68d588a542620e16368e4fd1a"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "a6dc621f8fc4f4558cb22289986a4886fe9e64c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/13\n",
      "85/85 [==============================] - 9s 112ms/step - loss: 0.6126 - acc: 0.7107 - val_loss: 0.8902 - val_acc: 0.6067\n",
      "Epoch 2/13\n",
      "85/85 [==============================] - 6s 70ms/step - loss: 0.5103 - acc: 0.7624 - val_loss: 0.8386 - val_acc: 0.5867\n",
      "Epoch 3/13\n",
      "85/85 [==============================] - 6s 70ms/step - loss: 0.5006 - acc: 0.7712 - val_loss: 0.7391 - val_acc: 0.6867\n",
      "Epoch 4/13\n",
      "85/85 [==============================] - 6s 70ms/step - loss: 0.4736 - acc: 0.7901 - val_loss: 1.0480 - val_acc: 0.7133\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 5/13\n",
      "85/85 [==============================] - 6s 70ms/step - loss: 0.4493 - acc: 0.8031 - val_loss: 0.4584 - val_acc: 0.7767\n",
      "Epoch 6/13\n",
      "85/85 [==============================] - 6s 70ms/step - loss: 0.4361 - acc: 0.8055 - val_loss: 0.4474 - val_acc: 0.8167\n",
      "Epoch 7/13\n",
      "85/85 [==============================] - 6s 70ms/step - loss: 0.4152 - acc: 0.8069 - val_loss: 0.4402 - val_acc: 0.8133\n",
      "Epoch 8/13\n",
      "85/85 [==============================] - 6s 70ms/step - loss: 0.3996 - acc: 0.8203 - val_loss: 0.5817 - val_acc: 0.6633\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 9/13\n",
      "85/85 [==============================] - 6s 71ms/step - loss: 0.4017 - acc: 0.8222 - val_loss: 0.4447 - val_acc: 0.8067\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=2, verbose=1, restore_best_weights=True)\n",
    "reducel = ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.1)\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=13,\n",
    "                   callbacks=[reducel, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "8c8099fc4994ae9792c74477711794c83db3aeee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7738666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "# make a prediction\n",
    "y_pred_keras = model.predict_generator(test_gen, steps=len(df_val), verbose=1)\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(test_gen.classes, y_pred_keras)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "auc_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_size = 1000\n",
    "image_size = 96\n",
    "import glob\n",
    "from PIL import Image\n",
    "process = lambda x:(x - x.mean()) / x.std() if x.std() > 0 else x\n",
    "import csv\n",
    "\n",
    "def get_id_from_filename(filename):\n",
    "    id = filename.split(\"/\")[-1]\n",
    "    id = id.split(\".\")[0]\n",
    "    return id\n",
    "\n",
    "def load_test():\n",
    "    names = []\n",
    "    # Change first number base on number of training examples\n",
    "    X_test = np.empty((test_data_size,image_size,image_size,3))\n",
    "    Y_test = np.empty(shape=(test_data_size,1))\n",
    "\n",
    "    i = 0\n",
    "    for filename in glob.glob('input/subset_data/test_with_outputs/*.tif'):\n",
    "        names.append(get_id_from_filename(filename))\n",
    "        img = Image.open(filename)\n",
    "        img.load()\n",
    "        img =np.asarray(img, dtype=\"int32\")\n",
    "        img = process(img)\n",
    "        X_test[i-1] = img\n",
    "        i += 1\n",
    "    with open('input/subset_data/train_labels_full.csv') as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        next(readCSV, None)\n",
    "        for row in readCSV:\n",
    "            name = row[0]\n",
    "            if name in names:\n",
    "                label = int(row[1])\n",
    "                if label == 0:\n",
    "                    Y_test[names.index(name)] = np.array([0]) # means 0\n",
    "                elif label == 1:\n",
    "                    Y_test[names.index(name)] = np.array([1]) # means 1\n",
    "    return X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_test.shape)\n",
    "# print(Y_test.shape)\n",
    "# print(X_test)\n",
    "# print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 767us/step\n",
      "\n",
      "Loss = 1.0525052814483642\n",
      "Test Accuracy = 0.521\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(x = X_test, y = Y_test)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f755d935752d007d21a59ac111cd0d604880c5fa"
   },
   "source": [
    "# Plot ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "2397d1c4956ea8615140b9cc40bb857e8a5deeae"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fpr_keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a69e583e88e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr_keras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_keras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'area = {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_keras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'False positive rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'True positive rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fpr_keras' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='area = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d52bccbbd7d4a8114b5bc9f53ce26db2601fa238"
   },
   "source": [
    "# Load test data and predict\n",
    "I could not find a smart way to do this without crashing the Kernel (due to MemoryError). So I just load the test files in batches, predict, and concatenate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "1ccdefc4770fa3b4d57c56990105173161471420"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-16447c3a4dca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbase_test_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../input/test/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_test_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'*.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "base_test_dir = '../input/test/'\n",
    "test_files = glob(os.path.join(base_test_dir,'*.tif'))\n",
    "submission = pd.DataFrame()\n",
    "file_batch = 5000\n",
    "max_idx = len(test_files)\n",
    "for idx in range(0, max_idx, file_batch):\n",
    "    print(\"Indexes: %i - %i\"%(idx, idx+file_batch))\n",
    "    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]})\n",
    "    test_df['id'] = test_df.path.map(lambda x: x.split('/')[3].split(\".\")[0])\n",
    "    test_df['image'] = test_df['path'].map(imread)\n",
    "    K_test = np.stack(test_df[\"image\"].values)\n",
    "    K_test = (K_test - K_test.mean()) / K_test.std()\n",
    "    predictions = model.predict(K_test)\n",
    "    test_df['label'] = predictions\n",
    "    submission = pd.concat([submission, test_df[[\"id\", \"label\"]]])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "c0c095619c41eb1996612d96e1ec3b147ebbe601"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-142254fb5679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submission.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'submission' is not defined"
     ]
    }
   ],
   "source": [
    "#submission\n",
    "# Delete the test_dir directory we created to prevent a Kaggle error.\n",
    "# Kaggle allows a max of 500 files to be saved.\n",
    "\n",
    "shutil.rmtree(train_path)\n",
    "shutil.rmtree(valid_path)\n",
    "submission.to_csv(\"submission.csv\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "357d239024be4067fa88d87ca0dc0202a59b9d1b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'submission.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6f812e5d2996>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'submission.csv' does not exist"
     ]
    }
   ],
   "source": [
    "pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
